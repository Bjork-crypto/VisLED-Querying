{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
    "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
    "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
    "\n",
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.utils.splits import create_splits_scenes\n",
    "\n",
    "from nuscenes import NuScenes\n",
    "import os\n",
    "import json\n",
    "from itertools import chain\n",
    "from typing import List\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from folder_creator import sample_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster and batch handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import clip\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Load the model and preprocess\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.files = [f for f in self.root_dir.iterdir() if f.suffix in ['.jpg', '.png', '.jpeg']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, str(img_path)\n",
    "\n",
    "def cluster_and_organize(cluster_path, new_cluster_path, threshold, classes, batch_size=32):\n",
    "    # Download the dataset\n",
    "    if not os.path.exists(cluster_path):\n",
    "            os.makedirs(cluster_path)\n",
    "\n",
    "    # Download the dataset\n",
    "    if not os.path.exists(new_cluster_path):\n",
    "            os.makedirs(new_cluster_path)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        preprocess,\n",
    "        lambda x: x.unsqueeze(0)\n",
    "    ])\n",
    "    dataset = ImageDataset(cluster_path, classes, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in classes]).to(device)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    for images, paths in tqdm(dataloader):\n",
    "        images = torch.cat(list(images), dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "            values , indices = torch.max(similarity, dim=-1)\n",
    "        for path, index, value in zip(paths, indices, values):\n",
    "            predicted_class = classes[index]\n",
    "            # if value < threshold:\n",
    "            #     predicted_class = 'unique'\n",
    "            destination_dir = Path(new_cluster_path) / predicted_class\n",
    "            destination_dir.mkdir(exist_ok=True)\n",
    "            shutil.copy(path, destination_dir)\n",
    "\n",
    "    print(f\"Images have been organized into clusters based on their top predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View amount of samples in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def cluster_length(cluster_path, classes):\n",
    "    cluster_path = Path(cluster_path)\n",
    "    # Download the dataset\n",
    "    # if not os.path.exists(cluster_path):\n",
    "    #         os.makedirs(cluster_path)\n",
    "    \n",
    "\n",
    "    for c in classes:\n",
    "        full_path = cluster_path / c\n",
    "        print(f\"{c} length: {len(os.listdir(full_path))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [#'car',\n",
    "                #'small car',\n",
    "                #'big car',\n",
    "                'bicycle',\n",
    "                'motorcycle', \n",
    "                'truck',\n",
    "                'trailer',\n",
    "                #'person',\n",
    "                #'barricade',\n",
    "                'traffic cone',\n",
    "                'bus',\n",
    "                'construction vehicle'\n",
    "                ]\n",
    "\n",
    "def copy_folder_contents(source_folder, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Iterate over the contents of the source folder\n",
    "    for item in os.listdir(source_folder):\n",
    "        # Form the paths to the source and destination items\n",
    "        source_item_path = os.path.join(source_folder, item)\n",
    "        destination_item_path = os.path.join(destination_folder, item)\n",
    "\n",
    "        # If it's a file, copy it directly\n",
    "        if os.path.isfile(source_item_path):\n",
    "            shutil.copy2(source_item_path, destination_item_path)\n",
    "        # If it's a folder, recursively copy its contents\n",
    "        elif os.path.isdir(source_item_path):\n",
    "            copy_folder_contents(source_item_path, destination_item_path)\n",
    "\n",
    "# Main function to process images and cluster them based on conceptual similarity using CLIP embeddings.\n",
    "def process_images(image_directory, clip_model, threshold, batch_size):\n",
    "    image_directory = Path(image_directory)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    embeddings_file = image_directory / 'embeddings.npy'\n",
    "    regenerate_embeddings = check_and_load_embeddings(embeddings_file)\n",
    "\n",
    "    # Load CLIP model and processor\n",
    "    model = CLIPModel.from_pretrained(clip_model).to(device)\n",
    "    processor = CLIPProcessor.from_pretrained(clip_model)\n",
    "    allowed_extensions = {\".jpeg\", \".jpg\", \".png\", \".webp\"}\n",
    "\n",
    "    images_to_paths, all_image_ids = get_images_to_paths(image_directory, allowed_extensions)\n",
    "    damaged_image_ids, all_embeddings = generate_embeddings(all_image_ids, images_to_paths, model, processor, device, batch_size, regenerate_embeddings, embeddings_file)\n",
    "\n",
    "    if regenerate_embeddings:\n",
    "        np.save(embeddings_file, all_embeddings)\n",
    "\n",
    "    print(\"Building Annoy index...\")\n",
    "    annoy_index = build_annoy_index(all_embeddings)\n",
    "\n",
    "    print(\"Computing distance matrix...\")\n",
    "    distances = compute_distance_matrix(all_embeddings, annoy_index)\n",
    "\n",
    "    print(\"Applying hierarchical clustering...\")\n",
    "    labels = apply_clustering(distances, threshold)\n",
    "\n",
    "    image_id_clusters = build_image_clusters(all_image_ids, labels)\n",
    "    organize_images(images_to_paths, image_directory, image_id_clusters, damaged_image_ids)\n",
    "\n",
    "# Check for existing embeddings file and load it if found, otherwise generate new embeddings\n",
    "def check_and_load_embeddings(embeddings_file):\n",
    "    if embeddings_file.exists():\n",
    "        use_existing_embeddings = input(\"Embeddings file found. Do you want to use existing embeddings? (Y/N) \").strip().lower()\n",
    "        if use_existing_embeddings in ('', 'y', 'yes'):\n",
    "            print(\"Loading embeddings from file...\")\n",
    "            all_embeddings = np.load(embeddings_file)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Get the paths of all images in the given directory and return the image ids and their paths\n",
    "def get_images_to_paths(image_directory, allowed_extensions):\n",
    "    images_to_paths = {\n",
    "        image_path.stem: image_path\n",
    "        for image_path in image_directory.iterdir()\n",
    "        if image_path.suffix.lower() in allowed_extensions\n",
    "    }\n",
    "    return images_to_paths, list(images_to_paths.keys())\n",
    "\n",
    "# Generate CLIP embeddings for all images, handling damaged images if any\n",
    "def generate_embeddings(all_image_ids, images_to_paths, model, processor, device, batch_size, regenerate_embeddings, embeddings_file):\n",
    "    if not regenerate_embeddings:\n",
    "        return set(), np.load(embeddings_file)\n",
    "\n",
    "    damaged_image_ids, all_embeddings = set(), []\n",
    "    progress_bar = tqdm(total=len(all_image_ids), desc=\"Generating CLIP embeddings\")\n",
    "\n",
    "    for i in range(0, len(all_image_ids), batch_size):\n",
    "        batch_image_ids, batch_images = process_image_batch(all_image_ids, i, batch_size, images_to_paths, damaged_image_ids)\n",
    "        inputs = processor(images=batch_images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.get_image_features(**inputs)\n",
    "\n",
    "        all_embeddings.extend(outputs.cpu().numpy())\n",
    "        progress_bar.update(len(batch_image_ids))\n",
    "\n",
    "    progress_bar.close()\n",
    "    return damaged_image_ids, all_embeddings\n",
    "\n",
    "# Process a batch of images, returning their ids and loaded images, while identifying damaged images\n",
    "def process_image_batch(all_image_ids, start_idx, batch_size, images_to_paths, damaged_image_ids):\n",
    "    batch_image_ids = all_image_ids[start_idx: start_idx + batch_size]\n",
    "    batch_images = []\n",
    "\n",
    "    for image_id in batch_image_ids:\n",
    "        try:\n",
    "            image = Image.open(images_to_paths[image_id])\n",
    "            image.load()\n",
    "            batch_images.append(image)\n",
    "        except OSError:\n",
    "            print(f\"\\nError processing image {images_to_paths[image_id]}, marking as corrupted.\")\n",
    "            damaged_image_ids.add(image_id)\n",
    "\n",
    "    return batch_image_ids, batch_images\n",
    "\n",
    "# Build an Annoy index using the generated CLIP embeddings\n",
    "def build_annoy_index(all_embeddings):\n",
    "    embeddings = np.array(all_embeddings)\n",
    "    n_dimensions = embeddings.shape[1]\n",
    "\n",
    "    annoy_index = AnnoyIndex(n_dimensions, \"angular\")\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        annoy_index.add_item(i, embedding)\n",
    "\n",
    "    annoy_index.build(100)\n",
    "    return annoy_index\n",
    "\n",
    "# Compute the distance matrix of the embeddings using the Annoy index\n",
    "def compute_distance_matrix(all_embeddings, annoy_index):\n",
    "    n = len(all_embeddings)\n",
    "    distances = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distance = annoy_index.get_distance(i, j)\n",
    "            distances.append(distance)\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Apply hierarchical clustering on the computed distance matrix with the given threshold\n",
    "def apply_clustering(distances, threshold):\n",
    "    condensed_distances = np.array(distances)\n",
    "    Z = linkage(condensed_distances, method='average', optimal_ordering=True)\n",
    "    return fcluster(Z, t=threshold, criterion='distance')\n",
    "\n",
    "# Build clusters of image ids based on the clustering labels\n",
    "def build_image_clusters(all_image_ids, labels):\n",
    "    image_id_clusters = defaultdict(set)\n",
    "\n",
    "    for image_id, cluster_label in zip(all_image_ids, labels):\n",
    "        image_id_clusters[cluster_label].add(image_id)\n",
    "\n",
    "    return image_id_clusters\n",
    "\n",
    "# Organize images into separate folders for clusters, unique images, and corrupted images\n",
    "def organize_images(images_to_paths, image_directory, image_id_clusters, damaged_image_ids):\n",
    "    for idx, image_id_cluster in enumerate(image_id_clusters.values()):\n",
    "        if len(image_id_cluster) < 2:\n",
    "            continue\n",
    "\n",
    "        move_images_to_directory(image_directory, f\"cluster_{idx}\", image_id_cluster, images_to_paths)\n",
    "\n",
    "    unique_image_ids = set(images_to_paths.keys()) - set(damaged_image_ids) - {image_id for cluster in image_id_clusters.values() for image_id in cluster if len(cluster) >= 2}\n",
    "    move_images_to_directory(image_directory, \"unique\", unique_image_ids, images_to_paths)\n",
    "\n",
    "    if damaged_image_ids:\n",
    "        move_images_to_directory(image_directory, \"corrupted\", damaged_image_ids, images_to_paths)\n",
    "\n",
    "# Move images to the specified folder within the image_directory\n",
    "def move_images_to_directory(image_directory, folder_name, image_ids, images_to_paths):\n",
    "    output_directory = image_directory / folder_name\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        source = images_to_paths[image_id]\n",
    "        destination = output_directory / source.name\n",
    "        shutil.move(source, destination)\n",
    "\n",
    "\n",
    "def count_folders_and_images(directory):\n",
    "    folder_count = 0\n",
    "    image_count = 0\n",
    "    valid_new_data = []\n",
    "\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        # If it's a directory, increment folder_count\n",
    "        if os.path.isdir(item_path) and item != \"unique\":\n",
    "            folder_path_name = os.path.join(directory, item)\n",
    "            for unique_item in os.listdir(folder_path_name):\n",
    "                valid_new_data += [unique_item[:unique_item.index(\".\")]]\n",
    "                break\n",
    "        # If it's a file and it's in the \"unique\" folder, check if it's an image\n",
    "        elif os.path.isdir(item_path) and item == \"unique\":\n",
    "            unique_folder = os.path.join(directory, item)\n",
    "            for unique_item in os.listdir(unique_folder):\n",
    "                unique_item_path = os.path.join(unique_folder, unique_item)\n",
    "                if os.path.isfile(unique_item_path):\n",
    "                    if unique_item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                        valid_new_data += [unique_item[:unique_item.index(\".\")]]\n",
    "\n",
    "    return valid_new_data\n",
    "\n",
    "\n",
    "def count_folders_and_images_not_found_in_training(directory, training_names):\n",
    "    # Check a folder.\n",
    "    # If no contents are already in the training set, then add these to the count.\n",
    "    # If they are in the training set, move to next folder.\n",
    "    folder_count = 0\n",
    "    image_count = 0\n",
    "    set_tnames = set(training_names)\n",
    "    valid_new_data = []\n",
    "    # Iterate over all items in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        # If it's a directory, increment folder_count\n",
    "        if os.path.isdir(item_path) and item != \"unique\":\n",
    "            folder_path_name = os.path.join(directory, item)\n",
    "            folder_items = []\n",
    "            for unique_item in os.listdir(folder_path_name):\n",
    "                unique_item_path = os.path.join(unique_folder, unique_item)\n",
    "                if os.path.isfile(unique_item_path):\n",
    "                    if unique_item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                        unique_item_training_name = unique_item[:unique_item.index(\".\")]\n",
    "                        folder_items += [unique_item_training_name]\n",
    "            # Find intersection of folder_items with training_names\n",
    "            set1 = set(folder_items)\n",
    "   \n",
    "\n",
    "            # Find the intersection of the two sets\n",
    "            intersection = set1.intersection(set_tnames)\n",
    "\n",
    "            if len(intersection) == 0:\n",
    "                valid_new_data += [unique_item[:unique_item.index(\".\")] for unique_item in os.listdir(folder_path_name)]\n",
    "           \n",
    "        # If it's a file and it's in the \"unique\" folder, check if it's an image\n",
    "        elif os.path.isdir(item_path) and item == \"unique\":\n",
    "            unique_folder = os.path.join(directory, item)\n",
    "            for unique_item in os.listdir(unique_folder):\n",
    "                unique_item_path = os.path.join(unique_folder, unique_item)\n",
    "                if os.path.isfile(unique_item_path):\n",
    "                    if unique_item.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')) and unique_item[:unique_item.index(\".\")] not in training_names:\n",
    "                        valid_new_data += [unique_item[:unique_item.index(\".\")]]\n",
    "\n",
    "    return valid_new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294/294 [04:56<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been organized into clusters based on their top predictions.\n",
      "bike length: 919\n",
      "motorcycle length: 476\n",
      "construction vehicle length: 1824\n",
      "bus length: 4638\n",
      "traffic cone length: 7967\n",
      "truck length: 3618\n",
      "trailer length: 8688\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 919/919 [00:24<00:00, 36.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 476/476 [00:12<00:00, 37.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 1824/1824 [00:49<00:00, 36.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 4638/4638 [02:05<00:00, 36.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 7967/7967 [03:38<00:00, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 3618/3618 [01:37<00:00, 37.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "Copying Images for Clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CLIP embeddings: 100%|██████████| 8688/8688 [03:56<00:00, 36.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Annoy index...\n",
      "Computing distance matrix...\n",
      "Applying hierarchical clustering...\n",
      "DONE!!!\n"
     ]
    }
   ],
   "source": [
    "# Source folder should contain all images you would like to cluster (and nothing else)\n",
    "# Destination folder will be created to hold the clustering results.\n",
    "orig_path = \"active_data/nuScenes_active\"\n",
    "source_path = \"/home/cvrr/Desktop/VLLM/active_data/zero-shot-clust/un_clustered\"\n",
    "dest_path = \"/home/cvrr/Desktop/VLLM/active_data/zero-shot-clust/clustered\"\n",
    "\n",
    "\n",
    "classes = [#'car',\n",
    "                #'small car',\n",
    "                #'big car',\n",
    "                #'bicycle',\n",
    "                'bike',\n",
    "                'motorcycle', \n",
    "                'construction vehicle',\n",
    "                'bus',\n",
    "                'traffic cone',\n",
    "                'truck',\n",
    "                'trailer',\n",
    "                #'person',\n",
    "                #'barricade',\n",
    "                ]\n",
    "\n",
    "cluster_and_organize(orig_path, source_path, 20, classes, batch_size=96)\n",
    "\n",
    "cluster_length(source_path, classes)\n",
    "\n",
    "\n",
    "for p in classes:\n",
    "\n",
    "    source_folder = os.path.join(source_path, p)\n",
    "    destination_folder = os.path.join(dest_path, f\"{p}_clustored\")\n",
    "\n",
    "\n",
    "    print(\"Copying Images for Clustering\")\n",
    "\n",
    "    copy_folder_contents(source_folder, destination_folder)\n",
    "\n",
    "    # Run the clustering algorithm with threshold t\n",
    "\n",
    "    experiment_image_directory = destination_folder\n",
    "\n",
    "\n",
    "    t_val = .5\n",
    "    #I like:\n",
    "    #.6\n",
    "    #.5\n",
    "    # .8 gave 1\n",
    "    # .7 gave 1\n",
    "    # .2 gave 19841 unique\n",
    "\n",
    "    experiment_image_directory = destination_folder\n",
    "\n",
    "    # First batch\n",
    "    \n",
    "    process_images(experiment_image_directory, \"openai/clip-vit-large-patch14-336\", t_val, 96)\n",
    "print('DONE!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity Sampling (First Round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "train_path = 'data/nuscenes/v1.0-trainval'\n",
    "test_path = 'data/nuscenes/v1.0-test'\n",
    "LLM_path = 'active_data/nuScenes_active'\n",
    "al_path = 'data/nuscenes'\n",
    "\n",
    "\n",
    "def file_opener(train_path):\n",
    "    # Load and prepare data\n",
    "    with open(os.path.join(train_path, 'orig_scene.json'), 'r') as f:\n",
    "        scene_data = json.load(f)\n",
    "    with open(os.path.join(train_path, 'orig_sample_data.json'), 'r') as f:\n",
    "        sample_data = json.load(f)\n",
    "    with open(os.path.join(train_path, 'orig_sample.json'), 'r') as f:\n",
    "        samples = json.load(f)\n",
    "\n",
    "    # Create mappings for quick lookup\n",
    "    filename_to_sample_token = {obj['filename'].split('/')[-1]: obj['sample_token'] for obj in sample_data}\n",
    "    sample_token_to_scene_token = {obj['token']: obj['scene_token'] for obj in samples}\n",
    "    scene_token_to_name = {obj['token']: obj['name'] for obj in scene_data}\n",
    "\n",
    "    return filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name\n",
    "\n",
    "def sample_extractor(sampled_image, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name):\n",
    "    # Lookup process\n",
    "    sample_token = filename_to_sample_token.get(sampled_image)\n",
    "    scene_token = sample_token_to_scene_token.get(sample_token)\n",
    "    scene_name = scene_token_to_name.get(scene_token)\n",
    "\n",
    "    # Output results\n",
    "    # print(f\"Sample token: {sample_token}\")\n",
    "    # print(f\"Scene token: {scene_token}\")\n",
    "    #print(f\"Scene name: {scene_name}\")\n",
    "    return scene_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_round_sampling_dynamic_selection(root_folder, chosen_folder, num_folders_to_select, train_path):\n",
    "    os.makedirs(os.path.join(root_folder, chosen_folder), exist_ok=True)\n",
    "    chosen_images = []\n",
    "    scene_names_set = set()\n",
    "\n",
    "    filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name = file_opener(train_path)\n",
    "\n",
    "    for class_folder in os.listdir(root_folder):\n",
    "        class_path = os.path.join(root_folder, class_folder)\n",
    "        all_cluster_folders = [name for name in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, name))]\n",
    "        random.shuffle(all_cluster_folders)\n",
    "        unvisited_cluster_folders = all_cluster_folders.copy()\n",
    "        selected_scenes_count = 0\n",
    "\n",
    "        while selected_scenes_count < num_folders_to_select and unvisited_cluster_folders:\n",
    "            selected_cluster_folder = unvisited_cluster_folders.pop(0)\n",
    "            selected_cluster_path = os.path.join(class_path, selected_cluster_folder)\n",
    "            images = [name for name in os.listdir(selected_cluster_path) if os.path.isfile(os.path.join(selected_cluster_path, name))]\n",
    "            random.shuffle(images)\n",
    "            image_found = False\n",
    "\n",
    "            for sampled_image in images:\n",
    "                scene_name = sample_extractor(sampled_image, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name)\n",
    "\n",
    "                if scene_name not in scene_names_set:\n",
    "                    image_path = os.path.join(selected_cluster_path, sampled_image)\n",
    "                    shutil.copy(image_path, os.path.join(root_folder, chosen_folder, sampled_image))\n",
    "                    chosen_images.append((sampled_image, class_folder, scene_name))\n",
    "                    scene_names_set.add(scene_name)\n",
    "                    selected_scenes_count += 1\n",
    "                    image_found = True\n",
    "                    break  # Exit after finding a unique scene\n",
    "            if not image_found:  # If no unique image was found, continue to the next folder\n",
    "                continue  # This will automatically move to the next iteration of the while loop\n",
    "\n",
    "        if selected_scenes_count < num_folders_to_select:\n",
    "            print(f\"Warning: Only {selected_scenes_count} unique scenes were found for class '{class_folder}', less than the desired {num_folders_to_select}.\")\n",
    "\n",
    "    print(\"Total unique scenes selected:\", len(scene_names_set))\n",
    "    return chosen_images, scene_names_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity Sampling (Subsequaint Rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Counts the number of image files in a given folder.\n",
    "\n",
    "    :param folder_path: Path to the folder.\n",
    "    :return: The count of image files.\n",
    "    \"\"\"\n",
    "    return len([name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))])\n",
    "\n",
    "def process_folder(folder_path, class_folder, chosen_images, scene_names_set, num_folders_to_select, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name, root_folder, chosen_folder):\n",
    "    import os\n",
    "    import shutil\n",
    "    import random\n",
    "\n",
    "    images = [name for name in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, name))]\n",
    "    random.shuffle(images)\n",
    "    scenes_added = 0  # Track the number of new scenes added\n",
    "\n",
    "    for sampled_image in images:\n",
    "        scene_name = sample_extractor(sampled_image, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name)\n",
    "        before_add_size = len(scene_names_set)  # Size of the set before attempting to add\n",
    "        scene_names_set.add(scene_name)  # Attempt to add the new scene\n",
    "        after_add_size = len(scene_names_set)  # Size of the set after attempting to add\n",
    "\n",
    "        if after_add_size > before_add_size:\n",
    "            # This means a new scene was successfully added\n",
    "            image_path = os.path.join(folder_path, sampled_image)\n",
    "            #shutil.copy(image_path, os.path.join(root_folder, chosen_folder, sampled_image))\n",
    "            chosen_images.append((sampled_image, os.path.basename(os.path.dirname(folder_path)), scene_name))\n",
    "            scenes_added += 1  # Increment only if a new scene was added\n",
    "\n",
    "            if scenes_added >= num_folders_to_select:\n",
    "                break  # Stop if the desired number of unique scenes is reached\n",
    "    if scenes_added < num_folders_to_select:\n",
    "        print(f\"Warning: Only {scenes_added} unique scenes were found for class '{class_folder}', less than the desired {num_folders_to_select}.\")\n",
    "\n",
    "    return scenes_added\n",
    "\n",
    "#The main function with added logic to prioritize the \"unique\" folder and sort remaining folders by image count\n",
    "def vislling_samples(root_folder, chosen_folder, num_folders_to_select, train_path, scene_names_set_prior):\n",
    "    import os\n",
    "    import shutil\n",
    "    import random\n",
    "    print(\"vislling being processes\")\n",
    "    print(\"amount of scenes present at start: \", len(scene_names_set_prior))\n",
    "    \n",
    "\n",
    "    os.makedirs(os.path.join(root_folder, chosen_folder), exist_ok=True)\n",
    "    chosen_images = []\n",
    "    scene_names_set = set(scene_names_set_prior)\n",
    "    print(\"Len Scene names\", len(scene_names_set))\n",
    "\n",
    "    filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name = file_opener(train_path)\n",
    "\n",
    "    #scene_name = sample_extractor(sampled_image, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name)\n",
    "\n",
    "\n",
    "    for class_folder in os.listdir(root_folder):\n",
    "        new_scenes_added = 0\n",
    "        class_path = os.path.join(root_folder, class_folder)\n",
    "        all_cluster_folders = [name for name in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, name))]\n",
    "        random.shuffle(all_cluster_folders)\n",
    "        #print(class_folder)\n",
    "        #print(all_cluster_folders)\n",
    "        \n",
    "\n",
    "        # #Calculate the remaining number of scenes to select for this class\n",
    "        # current_class_scenes = sum(1 for img in scene_names_set if img[1] == class_folder)  # Assuming each scene is a tuple (image, class, scene_name)\n",
    "        # num_folders_to_select = total_scenes_desired - current_class_scenes\n",
    "\n",
    "        # Process the \"unique\" folder first if it exists\n",
    "        if \"unique\" in all_cluster_folders:\n",
    "            all_cluster_folders.remove(\"unique\")\n",
    "            #process_folder(os.path.join(class_path, \"unique\"), chosen_images, scene_names_set, num_folders_to_select)\n",
    "            new_scenes_added += process_folder(os.path.join(class_path, \"unique\"), class_folder, chosen_images, scene_names_set, num_folders_to_select, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name, root_folder, chosen_folder)\n",
    "\n",
    "        # Sort remaining folders by image count\n",
    "        sorted_folders = sorted(all_cluster_folders, key=lambda folder: count_images_in_folder(os.path.join(class_path, folder)))\n",
    "\n",
    "        #Process sorted folders\n",
    "        for folder in sorted_folders:\n",
    "            #print(folder)\n",
    "            if new_scenes_added >= num_folders_to_select:\n",
    "                #print(new_scenes_added)\n",
    "                break  # Exit if we've reached the desired scene count\n",
    "            print(f\"processing scenes from other folders, for class {class_folder}\")\n",
    "            new_scenes_added += process_folder(os.path.join(class_path, folder), class_folder, chosen_images, scene_names_set, num_folders_to_select, filename_to_sample_token, sample_token_to_scene_token, scene_token_to_name, root_folder, chosen_folder)\n",
    "\n",
    "        #print(f\"Total unique scenes selected for class '{class_folder}': {len(scene_names_set)}\")\n",
    "\n",
    "    print(\"Overall total unique scenes selected:\", len(scene_names_set))\n",
    "    return chosen_images, scene_names_set\n",
    "\n",
    "\n",
    "\n",
    "#Note: Actual implementations for file_opener, sample_extractor, and process_folder need to be defined.\n",
    "#These stubs are placeholders for the logic that would be implemented based on the user's existing code and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only 0 unique scenes were found for class 'chosen', less than the desired 14.\n",
      "Total unique scenes selected: 98\n",
      "vislling being processes\n",
      "amount of scenes present at start:  98\n",
      "Len Scene names 98\n",
      "Overall total unique scenes selected: 203\n",
      "vislling being processes\n",
      "amount of scenes present at start:  203\n",
      "Len Scene names 203\n",
      "Overall total unique scenes selected: 301\n",
      "vislling being processes\n",
      "amount of scenes present at start:  301\n",
      "Len Scene names 301\n",
      "Overall total unique scenes selected: 399\n",
      "vislling being processes\n",
      "amount of scenes present at start:  399\n",
      "Len Scene names 399\n",
      "Warning: Only 12 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class motorcycle_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'motorcycle_clustored', less than the desired 15.\n",
      "Warning: Only 2 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 0 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "processing scenes from other folders, for class bike_clustored\n",
      "Warning: Only 1 unique scenes were found for class 'bike_clustored', less than the desired 15.\n",
      "Overall total unique scenes selected: 504\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "root_folder = \"/home/cvrr/Desktop/VLLM/active_data/zero-shot-clust/clustered\"  # Root folder containing class folders\n",
    "chosen_folder = 'chosen'  # Folder to save the chosen images\n",
    "num_folders_to_select = 14  # Number of cluster folders to select\n",
    "train_path = 'data/nuscenes/v1.0-trainval'\n",
    "\n",
    "#chosen_images = first_round_sampling(root_folder, chosen_folder, num_folders_to_select, train_path)\n",
    "chosen_images, scene_names_set = first_round_sampling_dynamic_selection(root_folder, chosen_folder, num_folders_to_select, train_path)\n",
    "#print(scene_names_set)\n",
    "#print(chosen_images)\n",
    "\n",
    "with open('splits/10p_diversity_split.json', 'w') as f:\n",
    "    json.dump(list(scene_names_set), f)\n",
    "\n",
    "scene_names_set_prior = scene_names_set\n",
    "num_folders_to_selects = [15, 14, 14, 15]  # Number of cluster folders to select\n",
    "\n",
    "\n",
    "pers = [20, 30, 40, 50]\n",
    "\n",
    "for per, num_folders_to_select in zip(pers, num_folders_to_selects):\n",
    "    chosen_images, scene_names_set = vislling_samples(root_folder, chosen_folder, num_folders_to_select, train_path, scene_names_set_prior)\n",
    "\n",
    "    with open(f'splits/{per}p_diversity_split.json', 'w') as f:\n",
    "        json.dump(list(scene_names_set), f)\n",
    "    scene_names_set_prior = scene_names_set\n",
    "\n",
    "#sample_extractor(chosen_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity Sampling (Other Rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike length: 758\n",
      "motorcycle length: 298\n",
      "truck length: 3255\n",
      "trailer length: 7722\n",
      "person length: 3117\n",
      "traffic cone length: 7036\n",
      "bus length: 4165\n",
      "construction vehicle length: 1779\n"
     ]
    }
   ],
   "source": [
    "classes = [#'car',\n",
    "                #'small car',\n",
    "                #'big car',\n",
    "                'bike',\n",
    "                'motorcycle', \n",
    "                'truck',\n",
    "                'trailer',\n",
    "                'person',\n",
    "                #'barricade',\n",
    "                'traffic cone',\n",
    "                'bus',\n",
    "                'construction vehicle'\n",
    "                ]\n",
    "\n",
    "clust_classes = [#'car',\n",
    "                #'small car',\n",
    "                #'big car',\n",
    "                'bike_clustored',\n",
    "                'motorcycle_clustored', \n",
    "                'truck_clustored',\n",
    "                'trailer_clustored',\n",
    "                'person_clustored',\n",
    "                #'barricade',\n",
    "                'traffic cone_clustored',\n",
    "                'bus_clustored',\n",
    "                'construction vehicle_clustored'\n",
    "                ]\n",
    "\n",
    "clust_path = \"/home/cvrr/Desktop/VLLM/active_data/zero-shot-clust/clustered\"\n",
    "path = \"/home/cvrr/Desktop/VLLM/active_data/zero-shot-clust/un_clustered\"\n",
    "\n",
    "\n",
    "#cluster_and_organize(\"active_data/nuScenes_active\", \"active_data/zero-shot-clust\", 20 ,classes)\n",
    "\n",
    "#cluster_length(clust_path, clust_classes)\n",
    "cluster_length(path, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
